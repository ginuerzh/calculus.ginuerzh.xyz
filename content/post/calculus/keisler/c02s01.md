+++
date = "2017-10-27T16:14:00+08:00"
categories = ["differentiation"]
tags = ["slope", "derivative", "differentiation", "differentiable"]
title = "2.1 Derivatives"
url = "calculus/keisler/02/01/"
+++

We are now ready to explain what is meant by the slope of a curve or the velocity of a moving point. Consider a real function \\(f\\) and a real number \\(a\\) in the domain of \\(f\\). When \\(x\\) has value \\(a\\), \\(f(x)\\) has value \\(f(a)\\). Now suppose the value of \\(x\\) is changed from \\(a\\) to a hyperreal number \\(a + \Delta{x}\\) which is infinitely close to but not equal to \\(a\\). Then the new value of \\(f(x)\\) will be \\(f(a + \Delta{x})\\). In this process the value of \\(x\\) will be changed by a nonzero infinitesimal amount \\(\Delta{x}\\), while the value of \\(f(x)\\) will be changed by the amount

$$
f(a + \Delta{x}) - f(a).
$$

The ratio of the change in the value of \\(f(x)\\) to the change in the value of \\(x\\) is

$$
\frac{f(a + \Delta{x}) - f(a)}{\Delta{x}}.
$$

This ratio is used in the definition of the slope of \\(f\\) which we now give.

**DEFINITION**

_\\(S\\) is said to be the **slope** of \\(f\\) at \\(a\\) if_

$$
S = st\Bigl(\frac{f(a + \Delta{x}) - f(a)}{\Delta{x}}\Bigr)
$$

_for every nonzero infinitesimal \\(\Delta{x}\\)_.

The slope, when it exists, is infinitely close to the ratio of the change in \\(f(x)\\) to an infinitely small change in \\(x\\). Given a curve \\(y = f(x)\\), the slope of \\(f\\) at \\(a\\) is also called the slope of the curve \\(y = f(x)\\) at \\(x = a\\). Figure 2.1.1 shows a nonzero infinitesimal \\(\Delta{x}\\) and a hyperreal straight line through the two points on the curve at \\(a\\) and \\(a + \Delta{x}\\). The quantity

$$
\frac{f(a + \Delta{x}) - f(a)}{\Delta{x}}
$$

is the slope of this line, and its standard part is the slope of the curve.

![figure 2.1.1](/img/calculus/keisler/f2.1.1.gif)

**Figure 2.1.1**

The slope of \\(f\\) at \\(a\\) does not always exist. Here is a list of all the possibilities.

(1) The slope of \\(f\\) at \\(a\\) exists if the ratio

$$
\frac{f(a + \Delta{x}) - f(a)}{\Delta{x}}
$$

is finite and has the same standard part for all infinitesimal \\(\Delta{x} \ne 0\\). It has the value

$$
S = st\Bigl(\frac{f(a + \Delta{x}) - f(a)}{\Delta{x}}\Bigr)
$$

(2) The slope of \\(f\\) at \\(a\\) can fail to exist in any of four ways:

(a) \\(f(a)\\) is undefined.

(b) \\(f(a + \Delta{x})\\) is undefined for some infinitesimal \\(\Delta{x} \ne 0\\).

\(c) The term \\(\frac{f(a + \Delta{x}) - f(a)}{\Delta{x}}\\) is infinite for some infinitesimal \\(\Delta{x} \ne 0\\).

(d) The term \\(\frac{f(a + \Delta{x}) - f(a)}{\Delta{x}}\\) has different standard parts for different infinitesimals \\(\Delta{x} \ne 0\\).

We can consider the slope of \\(f\\) at any point \\(x\\), which gives us a new function of \\(x\\).

**DEFINITION**

_Let f be a real function of one variable. The **derivative** of \\(f\\) is the new function \\(f^\prime\\) whose value at \\(x\\) is the slope of \\(f\\) at \\(x\\). In symbols,_

$$
f^\prime(x) = st\Bigl(\frac{f(x + \Delta{x}) - f(x)}{\Delta{x}}\Bigr)
$$

_whenever the slope exists._

The derivative \\(f^\prime(x)\\) is undefined if the slope of \\(f\\) does not exist at \\(x\\).

For a given point \\(a\\), the slope of \\(f\\) at \\(a\\) and the derivative of \\(f\\) at \\(a\\) are the same thing. We usually use the word "slope" to emphasize the geometric picture and "derivative" to emphasize the fact that \\(f^\prime\\) is a function.

The process of finding the derivative of \\(f\\) is called _differentiation_. We say that \\(f\\) is _differentiable_ at \\(a\\) if \\(f^\prime(a)\\) is defined; i.e., the slope of \\(f\\) at \\(a\\) exists.

Independent and dependent variables are useful in the study of derivatives. Let us briefly review what they are. A _system of formulas_ is a finite set of equations and inequalities. If we are given a system of formulas which has the same graph as a simple equation \\(y = f(x)\\) we say that \\(y\\) _is a function of_ \\(x\\), or that \\(y\\) _depends on_ \\(x\\), and we call \\(x\\) the _independent variable_ and \\(y\\) the _dependent variable_.

When \\(y = f(x)\\), we introduce a new independent variable \\(\Delta{x}\\) and a new dependent variable \\(\Delta{y}\\), with the equation

**(1)**

$$
\Delta{y} = f(x + \Delta{x}) - f(x).
$$

This equation determines \\(\Delta{y}\\) as a real function of the two variables \\(x\\) and \\(\Delta{x}\\), when \\(x\\) and \\(\Delta{x}\\) vary over the real numbers. We shall usually want to use the Equation 1 for \\(\Delta{y}\\) when \\(x\\) is a real number and \\(\Delta{x}\\) is a nonzero infinitesimal. The Transfer Principle implies that Equation 1 also determines \\(\Delta{y}\\) as a hyperreal function of two variables when \\(x\\) and \\(\Delta{x}\\) are allowed to vary over the hyperreal numbers.

\\(\Delta{y}\\) is called the _increment_ of \\(y\\). Geometrically, the increment \\(\Delta{y}\\) is the change in \\(y\\) along the curve corresponding to the change \\(\Delta{x}\\) in \\(x\\). The symbol \\(y^\prime\\) is sometimes used for the derivative, \\(y^\prime = f^\prime(x)\\). Thus the hyperreal equation

$$
f^\prime(x) = st\Bigl(\frac{f(x + \Delta{x}) - f(x)}{\Delta{x}}\Bigr)
$$

now takes the short form

$$
y^\prime = st\Bigl(\frac{\Delta{y}}{\Delta{x}}\Bigr).
$$

The infinitesimal \\(\Delta{x}\\) may be either positive or negative, but not zero. The various possibilities are illustrated in Figure 2.1.2 using an infinitesimal microscope. The signs of \\(\Delta{x}\\) and \\(\Delta{y}\\) are indicated in the captions.

![figure 2.1.2](/img/calculus/keisler/f2.1.2.gif)

**Figure 2.1.2**

Our rules for standard parts can be used in many cases to find the derivative of a function. There are two parts to the problem of finding the derivative \\(f^\prime\\) of a function \\(f\\):

(1) Find the domain of \\(f^\prime\\).

(2) Find the value of \\(f^\prime(x)\\) when it is defined.

**EXAMPLE 1**

Find the derivative of the function

$$
f(x) = x^3.
$$

In this and the following examples we let \\(x\\) vary over the real numbers and \\(\Delta{x}\\) vary over the nonzero infinitesimals. Let us introduce the new variable \\(y\\) with the equation \\(y = x^3\\). We first find \\(\frac{\Delta{y}}{\Delta{x}}\\).

$$
f(x) = x^3,
$$

$$
y + \Delta{y} = (x + \Delta{x})^3,
$$

$$
\Delta{y} = (x + \Delta{x})^3 - x^3,
$$

$$
\frac{\Delta{y}}{\Delta{x}} = \frac{(x + \Delta{x})^3 - x^3}{\Delta{x}}.
$$

Next we simplify the expression for \\(\frac{\Delta{y}}{\Delta{x}}\\).

$$
\frac{\Delta{y}}{\Delta{x}} = \frac{(x^3 + 3x^2\Delta{x} + 3x(\Delta{x})^2 + (\Delta{x})^3) - x^3}{\Delta{x}}
$$

$$
= \frac{3x^2\Delta{x} + 3x(\Delta{x})^2 + (\Delta{x})^3}{\Delta{x}}
$$

$$
= 3x^2 + 3x\Delta{x} + (\Delta{x})^2.
$$

Then we take the standard part.

$$
st(\frac{\Delta{y}}{\Delta{x}}) = st(3x^2 + 3x\Delta{x} + (\Delta{x})^2)
$$

$$
= st(3x^2) + st(3x\Delta{x}) + st((\Delta{x})^2)
$$

$$
= 3x^2 + 0 + 0 = 3x^2.
$$

Therefore,

$$
f^\prime(x) = st(\frac{\Delta{y}}{\Delta{x}}) = 3x^2.
$$

We have shown that the derivative of the function

$$
f(x) = x^3
$$

is the function

$$
f^\prime(x) = 3x^2
$$

with the whole real line as domain, \\(f(x)\\) and \\(f^\prime(x)\\) are shown in Figure 2.1.3.

![figure 2.1.3](/img/calculus/keisler/f2.1.3.gif)

**Figure 2.1.3**

**EXAMPLE 2**

Find \\(f^\prime(x)\\) given \\(f(x) = \sqrt{x}\\).

_Case 1_

\\(x < 0\\). Since \\(\sqrt{x}\\) is not defined, \\(f^\prime(x)\\) does not exist.

_Case 2_

\\(x = 0\\). When \\(\Delta{x}\\) is a negative infinitesimal, the term

$$
\frac{\sqrt{x + \Delta{x}} - \sqrt{x}}{\Delta{x}} = \frac{\sqrt{0 + \Delta{x}} - \sqrt{0}}{\Delta{x}}
$$

is not defined because \\(\sqrt{\Delta{x}}\\) is undefined. When \\(\Delta{x}\\) is a positive infinitesimal, the term

$$
\frac{\sqrt{x + \Delta{x}} - \sqrt{x}}{\Delta{x}} = \frac{\sqrt{\Delta{x}}}{\Delta{x}} = \frac{1}{\sqrt{\Delta{x}}}
$$

is defined but its value is infinite. Thus for two reasons, \\(f^\prime(x)\\) does not exist.

_Case 3_

\\(x > 0\\). Let \\(y = \sqrt{x}\\). Then

$$
y + \Delta{y} = \sqrt{x + \Delta{x}},
$$

$$
\Delta{y} = \sqrt{x + \Delta{x}} - \sqrt{x},
$$

$$
\frac{\Delta{y}}{\Delta{x}} = \frac{\sqrt{x + \Delta{x}} - \sqrt{x}}{\Delta{x}}.
$$

We then make the computation

$$
\frac{\Delta{y}}{\Delta{x}} = \frac{(\sqrt{x + \Delta{x}} - \sqrt{x})}{\Delta{x}} \cdot \frac{(\sqrt{x + \Delta{x}} + \sqrt{x})}{(\sqrt{x + \Delta{x}} + \sqrt{x})}
$$

$$
= \frac{(x + \Delta{x}) - x}{\Delta{x}(\sqrt{x + \Delta{x}} + \sqrt{x})}
$$

$$
= \frac{\Delta{x}}{\Delta{x}(\sqrt{x + \Delta{x}} + \sqrt{x})} = \frac{1}{\sqrt{x + \Delta{x}} + \sqrt{x}}
$$

Taking standard parts,

$$
st\Bigl(\frac{\Delta{y}}{\Delta{x}}\Bigr) = st\Bigl(\frac{1}{\sqrt{x + \Delta{x}} + \sqrt{x}}\Bigr)
$$

$$
= \frac{1}{st(\sqrt{x + \Delta{x}} + \sqrt{x})}
$$

$$
= \frac{1}{st(\sqrt{x + \Delta{x}}) + st(\sqrt{x})}
$$

$$
= \frac{1}{\sqrt{x} + \sqrt{x}} = \frac{1}{2\sqrt{x}}.
$$

Therefore, when \\(x > 0\\),

$$
f^\prime(x) = \frac{1}{2\sqrt{x}}.
$$

So the derivative of 

$$
f(x) = \sqrt{x}
$$

is the function

$$
f^\prime(x) = \frac{1}{2\sqrt{x}},
$$

and the set of all \\(x > 0\\) is its domain (see Figure 2.1.4).

![figure 2.1.4](/img/calculus/keisler/f2.1.4.gif)

**Figure 2.1.4**

**EXAMPLE 3**

Find the deritative of \\(f(x) = 1/x\\).

_Case 1_

\\(x = 0\\). Then \\(1/x\\) is undefined so \\(f^\prime(x)\\) is undefined.

_Case 2_

\\(x \ne 0\\).

$$
y = 1/x,
$$

$$
y + \Delta{y} = \frac{1}{x + \Delta{x}},
$$

$$
\Delta{y} = \frac{1}{x + \Delta{x}} - \frac{1}{x},
$$

$$
\frac{\Delta{y}}{\Delta{x}} = \frac{1/(x + \Delta{x}) - 1/x}{\Delta{x}}.
$$

Simplifying,

$$
\frac{1/(x + \Delta{x}) - 1/x}{\Delta{x}} = \frac{x - (x + \Delta{x})}{x(x + \Delta{x})\Delta{x}}
$$

$$
= \frac{-\Delta{x}}{x(x + \Delta{x})\Delta{x}} = \frac{-1}{x(x + \Delta{x})}.
$$

Taking the standard part,

$$
st\Bigl(\frac{\Delta{y}}{\Delta{x}}\Bigr) = st\Bigl(-\frac{1}{x(x + \Delta{x})}\Bigr)
$$

$$
= -\frac{1}{st(x(x + \Delta{x}))}
$$

$$
= -\frac{1}{st(x)st(x + \Delta{x})}
$$

$$
= -\frac{1}{x \cdot x} = -\frac{1}{x^2}.
$$

Thus

$$
f^\prime(x) = -1/x^2.
$$

The deritative of the function \\(f(x) = 1/x\\) is the function \\(f^\prime(x) = -1/x^2\\) whose domain is the set of all \\(x \ne 0\\). Both functions are graphed in Figure 2.1.5.

![figure 2.1.5](/img/calculus/keisler/f2.1.5.gif)

**Figure 2.1.5**

**EXAMPLE 4**

Find the derivative of \\(f(x) = |x|\\).

_Case 1_

\\(x > 0\\). In this case \\(|x| = x\\), and we have

$$
y = x,
$$

$$
y + \Delta{y} = x + \Delta{x},
$$

$$
\Delta{y} = \Delta{x},
$$

$$
\frac{\Delta{y}}{\Delta{x}} = 1, f^\prime(x) = 1.
$$

_Case 2_

\\(x < 0\\). Now \\(|x| = -x\\), and

$$
y = -x,
$$

$$
y + \Delta{y} = -(x + \Delta{x}),
$$

$$
\Delta{y} = -(x + \Delta{x}) - (-x) = -\Delta{x},
$$

$$
\frac{\Delta{y}}{\Delta{x}} = -\frac{\Delta{x}}{\Delta{x}}, f^\prime(x) = -1.
$$

_Case 3_

\\(x = 0\\). Then

$$
y = 0,
$$

$$
y + \Delta{y} = |0 + \Delta{x}| = |\Delta{x}|,
$$

$$
\Delta{y} = |\Delta{x}|,
$$

and

$$
\frac{\Delta{y}}{\Delta{x}} = \frac{|\Delta{x}|}{\Delta{x}} = \begin{cases} 1 &\text{if } \Delta{x} > 0, \cr  -1 &\text{if } \Delta{x} < 0, \end{cases}
$$

The standard part of \\(\Delta{y}/\Delta{x}\\) is then \\(1\\) for some values of \\(\Delta{x}\\) and \\(-1\\) for others. Therefore \\(f^\prime(x)\\) does not exist when \\(x = 0\\).

In summary,

$$
f^\prime(x) = \begin{cases} 1 &\text{if } x > 0, \cr  -1 &\text{if } x < 0, \cr undefined &\text{if } x = 0. \end{cases}
$$

Figure 2.1.6 shows \\(f(x)\\) and \\(f^\prime(x)\\).

![figure 2.1.6](/img/calculus/keisler/f2.1.6.gif)

**Figure 2.1.6**

The derivative has a variety of applications to the physical, life, and social sciences. It may come up in one of the following contexts.

_Velocity_: If an object moves according to the equation \\(s = f(t)\\) where \\(t\\) is time and \\(s\\) is distance, the derivative \\(v = f^\prime(t)\\) is called the _velocity_ of the object at time \\(t\\).

_Growth rates_: A population \\(y\\) (of people, bacteria, molecules, etc.) grows according to the equation \\(y = f(t)\\) where \\(t\\) is time. Then the derivative \\(y^\prime = f^\prime(t)\\) is the _rate of growth_ of the population \\(y\\) at time \\(t\\).

_Marginal values_ (economics): Suppose the total cost (or profit, etc.) of producing \\(x\\) items is \\(y = f(x)\\) dollars. Then the cost of making one additional item is approximately the derivative \\(y^\prime = f^\prime(x)\\) because \\(y^\prime\\) is the change in \\(y\\) per unit change in \\(x\\). This derivative is called the _marginal_ cost.

**EXAMPLE 5**

A ball thrown upward with initial velocity \\(b\\) ft per sec will be at a height

$$
y = bt - 16t^2
$$

feet after \\(t\\) seconds. Find the velocity at time \\(t\\). Let \\(t\\) be real and \\(\Delta{t} \ne 0\\), infinitesimal.

$$
y + \Delta{y} = b(t + \Delta{t}) - 16(t + \Delta{t})^2,
$$

$$
\Delta{y} = [b(t + \Delta{t}) - 16(t + \Delta{t})^2] - [bt - 16t^2],
$$

$$
\frac{\Delta{y}}{\Delta{t}} = \frac{[b(t + \Delta{t}) - 16(t + \Delta{t})^2] - [bt - 16t^2]}{\Delta{t}}
$$

$$
= \frac{b \Delta{t} - 32t \Delta{t} - 16(\Delta{t})^2}{\Delta{t}}
$$

$$
= b - 32t - 16\Delta{t}.
$$

$$
st\Bigl(\frac{\Delta{y}}{\Delta{x}}\Bigr) = st(b - 32t - 16\Delta{t})
$$

$$
= st(b - 32t) - st(16\Delta{t})
$$

$$
= b - 32t - 0 = b - 32t.
$$

At time \\(t\\) sec, \\(v = y^\prime = b - 32t\\) ft/sec.

Both functions are graphed in Figure 2.1.7.

![figure 2.1.7](/img/calculus/keisler/f2.1.7.gif)

**Figure 2.1.7**

**EXAMPLE 6**

Suppose a bacterial culture grows in such a way that at time \\(t\\) there are \\(t^3\\) bacteria. Find the rate of growth at time \\(t = 1000\\) sec.

$$
y = t^3 
$$

$$
y^\prime = 3t^2
$$

by Example 1.

At \\(t = 1000\\), \\(y^\prime = 3,000,000\\) bacteria/sec.

**EXAMPLE 7**

Suppose the cost of making \\(x\\) needles is \\(\sqrt{x}\\) dollars. What is the marginal cost after 10,000 needles have been made?

$$
y = \sqrt{x},
$$

$$
y^\prime = \frac{1}{2\sqrt{x}}
$$

by Example 2. 

At \\(x = 10,000\\), \\(y^\prime = \frac{1}{2\sqrt{10,000}} = \frac{1}{200}\\) dollars per needle.

Thus the marginal cost is one half of a cent per needle.